{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qkb6bYy3rOx"
      },
      "source": [
        "\n",
        "\n",
        "* Author: Zhuoning Yuan\n",
        "* Project: https://github.com/yzhuoning/LibAUC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTJ3ca0u4YQ4"
      },
      "source": [
        "# **Installing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt30xbSr1GAU",
        "outputId": "24097f89-dd23-4f8b-e18d-af3d98c0fc76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is CUDA supported by this system? True\n",
            "CUDA version: 11.3\n",
            "ID of current CUDA device:0\n",
            "Name of current CUDA device:Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "  \n",
        "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "  \n",
        "# Storing ID of current CUDA device\n",
        "cuda_id = torch.cuda.current_device()\n",
        "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
        "        \n",
        "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmGDrHnt3tqp",
        "outputId": "2df5e69b-43fc-4c0c-affd-d6133146efd5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h8iVw1kU3guh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4513b63a-f334-474a-9a96-d559c7684b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: libauc in /usr/local/lib/python3.7/dist-packages (1.1.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from libauc) (4.1.2.30)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from libauc) (1.3.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from libauc) (0.18.3)\n",
            "Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from libauc) (2.8.0+zzzcolab20220506162203)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from libauc) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from libauc) (1.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from libauc) (7.1.2)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from libauc) (1.11.0+cu113)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (1.1.2)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (1.14.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (4.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (1.46.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (14.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->libauc) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->libauc) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.0.0->libauc) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->libauc) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->libauc) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->libauc) (2022.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->libauc) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->libauc) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->libauc) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->libauc) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->libauc) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->libauc) (2021.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->libauc) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->libauc) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->libauc) (1.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->libauc) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->libauc) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install libauc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlD-4SrE4dVW"
      },
      "source": [
        "# **Downloading CheXpert**\n",
        " \n",
        "*   To request dataset access, you need to apply from CheXpert website: https://stanfordmlgroup.github.io/competitions/chexpert/\n",
        "*   In this tutorial, we use the smaller version of dataset with lower image resolution, i.e., *CheXpert-v1.0-small.zip*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CcsJ4eoj3VST"
      },
      "outputs": [],
      "source": [
        "# !cp /content/gdrive/MyDrive/chexpert-dataset/CheXpert-v1.0-small.zip /content/\n",
        "# !mkdir CheXpert\n",
        "# !unzip CheXpert-v1.0-small.zip -d /content/CheXpert/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVvrt3ku4qpq"
      },
      "source": [
        "\n",
        "# **Importing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Deep Learning Project/CheXpert-v1.0-small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSYn3bR84MSk",
        "outputId": "1b38e116-29c0-4ab1-e9a7-5bed80511ffb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep Learning Project/CheXpert-v1.0-small\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XGHWer3v4qJo"
      },
      "outputs": [],
      "source": [
        "from libauc.losses import AUCMLoss, CrossEntropyLoss\n",
        "from libauc.optimizers import PESG, Adam\n",
        "from libauc.models import DenseNet121, DenseNet169, ResNet18,ResNet50, ResNet34, ResNet56\n",
        "from libauc.datasets import CheXpert\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UUiwIdJ1GAa",
        "outputId": "5cf4717c-ada6-4213-a4eb-c37b5a708915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install GPUtil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UIrYZPNv1GAb"
      },
      "outputs": [],
      "source": [
        "from GPUtil import showUtilization as gpu_usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2swK5Mo7Kca"
      },
      "source": [
        "# **Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OiiT5oEp7J3C"
      },
      "outputs": [],
      "source": [
        "# def set_all_seeds(SEED):\n",
        "#     # REPRODUCIBILITY\n",
        "#     torch.manual_seed(SEED)\n",
        "#     np.random.seed(SEED)\n",
        "#     torch.backends.cudnn.deterministic = True\n",
        "#     torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Bge6KM7lBP"
      },
      "source": [
        "# **Pretraining**\n",
        "* Multi-label classification (5 tasks)   \n",
        "* Adam + CrossEntropy Loss \n",
        "* This step is optional\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "wInsw0yTTqfJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "piywwgmLRdJ-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_root = '/content/drive/MyDrive/Deep Learning Project/CheXpert-v1.0-small/'\n",
        "# df = pd.read_csv (data_root + 'train.csv')\n",
        "# df = df.fillna(0)\n",
        "# train_df = df[:3000]\n",
        "# valid_df = df[1000:1500]\n",
        "# test_df = df[1500:2000]\n",
        "# print(train_df.shape)\n",
        "# print(valid_df.shape)\n",
        "# print(test_df.shape)"
      ],
      "metadata": {
        "id": "8dWfG6cuRhJh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df.to_csv(r'Chexpert_train.csv', index=False)\n",
        "# valid_df.to_csv(r'Chexpert_valid.csv', index=False)\n",
        "# test_df.to_csv(r'Chexpert_test.csv', index=False)"
      ],
      "metadata": {
        "id": "6v3256mVTown"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkKcegEh72VP",
        "outputId": "890c0549-543c-42fb-87b8-d89c7b27d0c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/libauc/datasets/chexpert.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
            "/usr/local/lib/python3.7/dist-packages/libauc/datasets/chexpert.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-label mode: True, Number of classes: [5]\n",
            "------------------------------\n",
            "Found 2384 images in total, 300 positive images, 2084 negative images\n",
            "Cardiomegaly(C0): imbalance ratio is 0.1258\n",
            "\n",
            "Found 2384 images in total, 695 positive images, 1689 negative images\n",
            "Edema(C1): imbalance ratio is 0.2915\n",
            "\n",
            "Found 2384 images in total, 147 positive images, 2237 negative images\n",
            "Consolidation(C2): imbalance ratio is 0.0617\n",
            "\n",
            "Found 2384 images in total, 687 positive images, 1697 negative images\n",
            "Atelectasis(C3): imbalance ratio is 0.2882\n",
            "\n",
            "Found 2384 images in total, 918 positive images, 1466 negative images\n",
            "Pleural Effusion(C4): imbalance ratio is 0.3851\n",
            "\n",
            "Multi-label mode: True, Number of classes: [5]\n",
            "------------------------------\n",
            "Found 398 images in total, 60 positive images, 338 negative images\n",
            "Cardiomegaly(C0): imbalance ratio is 0.1508\n",
            "\n",
            "Found 398 images in total, 107 positive images, 291 negative images\n",
            "Edema(C1): imbalance ratio is 0.2688\n",
            "\n",
            "Found 398 images in total, 25 positive images, 373 negative images\n",
            "Consolidation(C2): imbalance ratio is 0.0628\n",
            "\n",
            "Found 398 images in total, 111 positive images, 287 negative images\n",
            "Atelectasis(C3): imbalance ratio is 0.2789\n",
            "\n",
            "Found 398 images in total, 171 positive images, 227 negative images\n",
            "Pleural Effusion(C4): imbalance ratio is 0.4296\n",
            "\n",
            "Epoch=0, BatchID=0, Val_AUC=0.5069, Best_Val_AUC=0.5069\n",
            "Epoch=0, BatchID=20, Val_AUC=0.6015, Best_Val_AUC=0.6015\n",
            "Epoch=0, BatchID=40, Val_AUC=0.6559, Best_Val_AUC=0.6559\n",
            "Epoch=0, BatchID=60, Val_AUC=0.6754, Best_Val_AUC=0.6754\n",
            "Epoch=0, BatchID=80, Val_AUC=0.7065, Best_Val_AUC=0.7065\n",
            "Epoch=0, BatchID=100, Val_AUC=0.7108, Best_Val_AUC=0.7108\n",
            "Epoch=0, BatchID=120, Val_AUC=0.7088, Best_Val_AUC=0.7108\n",
            "Epoch=0, BatchID=140, Val_AUC=0.7067, Best_Val_AUC=0.7108\n",
            "Epoch=0, BatchID=160, Val_AUC=0.7150, Best_Val_AUC=0.7150\n",
            "Epoch=0, BatchID=180, Val_AUC=0.7386, Best_Val_AUC=0.7386\n",
            "Epoch=0, BatchID=200, Val_AUC=0.7436, Best_Val_AUC=0.7436\n",
            "Epoch=0, BatchID=220, Val_AUC=0.7572, Best_Val_AUC=0.7572\n",
            "Epoch=1, BatchID=0, Val_AUC=0.7618, Best_Val_AUC=0.7618\n",
            "Epoch=1, BatchID=20, Val_AUC=0.7729, Best_Val_AUC=0.7729\n",
            "Epoch=1, BatchID=40, Val_AUC=0.7712, Best_Val_AUC=0.7729\n",
            "Epoch=1, BatchID=60, Val_AUC=0.7722, Best_Val_AUC=0.7729\n",
            "Epoch=1, BatchID=80, Val_AUC=0.7877, Best_Val_AUC=0.7877\n",
            "Epoch=1, BatchID=100, Val_AUC=0.7937, Best_Val_AUC=0.7937\n",
            "Epoch=1, BatchID=120, Val_AUC=0.7899, Best_Val_AUC=0.7937\n",
            "Epoch=1, BatchID=140, Val_AUC=0.7815, Best_Val_AUC=0.7937\n",
            "Epoch=1, BatchID=160, Val_AUC=0.7779, Best_Val_AUC=0.7937\n",
            "Epoch=1, BatchID=180, Val_AUC=0.8060, Best_Val_AUC=0.8060\n",
            "Epoch=1, BatchID=200, Val_AUC=0.8168, Best_Val_AUC=0.8168\n",
            "Epoch=1, BatchID=220, Val_AUC=0.8213, Best_Val_AUC=0.8213\n",
            "Epoch=2, BatchID=0, Val_AUC=0.8279, Best_Val_AUC=0.8279\n",
            "Epoch=2, BatchID=20, Val_AUC=0.8259, Best_Val_AUC=0.8279\n",
            "Epoch=2, BatchID=40, Val_AUC=0.8232, Best_Val_AUC=0.8279\n",
            "Epoch=2, BatchID=60, Val_AUC=0.8343, Best_Val_AUC=0.8343\n",
            "Epoch=2, BatchID=80, Val_AUC=0.8339, Best_Val_AUC=0.8343\n",
            "Epoch=2, BatchID=100, Val_AUC=0.8415, Best_Val_AUC=0.8415\n",
            "Epoch=2, BatchID=120, Val_AUC=0.8340, Best_Val_AUC=0.8415\n",
            "Epoch=2, BatchID=140, Val_AUC=0.8388, Best_Val_AUC=0.8415\n",
            "Epoch=2, BatchID=160, Val_AUC=0.8458, Best_Val_AUC=0.8458\n",
            "Epoch=2, BatchID=180, Val_AUC=0.8559, Best_Val_AUC=0.8559\n",
            "Epoch=2, BatchID=200, Val_AUC=0.8682, Best_Val_AUC=0.8682\n",
            "Epoch=2, BatchID=220, Val_AUC=0.8836, Best_Val_AUC=0.8836\n",
            "Epoch=3, BatchID=0, Val_AUC=0.8814, Best_Val_AUC=0.8836\n",
            "Epoch=3, BatchID=20, Val_AUC=0.8780, Best_Val_AUC=0.8836\n",
            "Epoch=3, BatchID=40, Val_AUC=0.8767, Best_Val_AUC=0.8836\n",
            "Epoch=3, BatchID=60, Val_AUC=0.8689, Best_Val_AUC=0.8836\n",
            "Epoch=3, BatchID=80, Val_AUC=0.8785, Best_Val_AUC=0.8836\n",
            "Epoch=3, BatchID=100, Val_AUC=0.8800, Best_Val_AUC=0.8836\n",
            "Epoch=3, BatchID=120, Val_AUC=0.8882, Best_Val_AUC=0.8882\n",
            "Epoch=3, BatchID=140, Val_AUC=0.8913, Best_Val_AUC=0.8913\n",
            "Epoch=3, BatchID=160, Val_AUC=0.8676, Best_Val_AUC=0.8913\n",
            "Epoch=3, BatchID=180, Val_AUC=0.8694, Best_Val_AUC=0.8913\n",
            "Epoch=3, BatchID=200, Val_AUC=0.8743, Best_Val_AUC=0.8913\n",
            "Epoch=3, BatchID=220, Val_AUC=0.8873, Best_Val_AUC=0.8913\n",
            "Epoch=4, BatchID=0, Val_AUC=0.8923, Best_Val_AUC=0.8923\n",
            "Epoch=4, BatchID=20, Val_AUC=0.8979, Best_Val_AUC=0.8979\n",
            "Epoch=4, BatchID=40, Val_AUC=0.9066, Best_Val_AUC=0.9066\n",
            "Epoch=4, BatchID=60, Val_AUC=0.9089, Best_Val_AUC=0.9089\n",
            "Epoch=4, BatchID=80, Val_AUC=0.9156, Best_Val_AUC=0.9156\n",
            "Epoch=4, BatchID=100, Val_AUC=0.9090, Best_Val_AUC=0.9156\n",
            "Epoch=4, BatchID=120, Val_AUC=0.9070, Best_Val_AUC=0.9156\n",
            "Epoch=4, BatchID=140, Val_AUC=0.9025, Best_Val_AUC=0.9156\n",
            "Epoch=4, BatchID=160, Val_AUC=0.9002, Best_Val_AUC=0.9156\n",
            "Epoch=4, BatchID=180, Val_AUC=0.9030, Best_Val_AUC=0.9156\n",
            "Epoch=4, BatchID=200, Val_AUC=0.9058, Best_Val_AUC=0.9156\n",
            "Epoch=4, BatchID=220, Val_AUC=0.9209, Best_Val_AUC=0.9209\n"
          ]
        }
      ],
      "source": [
        "# dataloader\n",
        "data_root = '/content/drive/MyDrive/Deep Learning Project/CheXpert-v1.0-small/'\n",
        "# Index: -1 denotes multi-label mode including 5 diseases\n",
        "traindSet = CheXpert(csv_path=data_root+'Chexpert_train.csv', image_root_path=data_root, use_upsampling=False, use_frontal=True, image_size=224, mode='train', class_index=-1)\n",
        "testSet =  CheXpert(csv_path=data_root+'Chexpert_valid.csv',  image_root_path=data_root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=-1)\n",
        "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=10, num_workers=2, shuffle=True)\n",
        "testloader =  torch.utils.data.DataLoader(testSet, batch_size=10, num_workers=2, shuffle=False)\n",
        "\n",
        "# paramaters\n",
        "SEED = 123\n",
        "BATCH_SIZE = 10\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-5\n",
        "\n",
        "# model\n",
        "#set_all_seeds(SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DenseNet121(pretrained=True, last_activation=None, activations='relu', num_classes=5)\n",
        "model = model.to(device)\n",
        "\n",
        "# define loss & optimizer\n",
        "CELoss = CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
        "# training\n",
        "best_val_auc = 0 \n",
        "for epoch in range(5):\n",
        "    for idx, data in enumerate(trainloader):\n",
        "      #with torch.no_grad():\n",
        "        #print(gpu_usage())\n",
        "        torch.cuda.empty_cache()\n",
        "        train_data, train_labels = data\n",
        "        train_data, train_labels  = train_data.to(device), train_labels.to(device)\n",
        "        y_pred = model(train_data)\n",
        "        loss = CELoss(y_pred, train_labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "            \n",
        "        # validation  \n",
        "        if idx % 20 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():    \n",
        "                test_pred = []\n",
        "                test_true = [] \n",
        "                for jdx, data in enumerate(testloader):\n",
        "                    test_data, test_labels = data\n",
        "                    test_data = test_data.to(device)\n",
        "                    y_pred = model(test_data)\n",
        "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
        "                    test_true.append(test_labels.numpy())\n",
        "                \n",
        "                test_true = np.concatenate(test_true)\n",
        "                test_pred = np.concatenate(test_pred)\n",
        "                val_auc_mean =  roc_auc_score(test_true, test_pred) \n",
        "                model.train()\n",
        "                #accuracy = accuracy_score(test_true,test_pred)\n",
        "                if best_val_auc < val_auc_mean:\n",
        "                    best_val_auc = val_auc_mean\n",
        "                    torch.save(model.state_dict(), '/content/drive/MyDrive/Gao Independent Study/Densenet121_pretrained_model.pth')\n",
        "\n",
        "                print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Val_AUC=%.4f, Best_Val_AUC=%.4f'%(val_auc_mean, best_val_auc ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxnybDs2CjNs",
        "outputId": "49fcf843-611f-4f71-f2cc-6a25362d611e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val_AUC=0.9209, Best_Val_AUC=0.9209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # dataloader\n",
        "# root = '/content/drive/MyDrive/Chexpert_Dataset/'\n",
        "data_root = '/content/drive/MyDrive/Deep Learning Project/CheXpert-v1.0-small/'\n",
        "traindSet = CheXpert(csv_path=data_root+'Chexpert_train.csv', image_root_path=data_root, use_upsampling=False, use_frontal=True, image_size=224, mode='train', class_index=-1)\n",
        "testSet =  CheXpert(csv_path=data_root+'Chexpert_valid.csv',  image_root_path=data_root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=-1)\n",
        "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=10, num_workers=2, shuffle=True)\n",
        "testloader =  torch.utils.data.DataLoader(testSet, batch_size=10, num_workers=2, shuffle=False)\n",
        "\n",
        "# # paramaters\n",
        "SEED = 123\n",
        "BATCH_SIZE = 10\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-5\n",
        "\n",
        "# # model\n",
        "# set_all_seeds(SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DenseNet169(pretrained=True, last_activation=None, activations='relu', num_classes=5)\n",
        "model = model.to(device)\n",
        "\n",
        "# define loss & optimizer\n",
        "CELoss = CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
        "# training\n",
        "best_val_auc = 0 \n",
        "for epoch in range(5):\n",
        "    for idx, data in enumerate(trainloader):\n",
        "      #with torch.no_grad():\n",
        "        #print(gpu_usage())\n",
        "        torch.cuda.empty_cache()\n",
        "        train_data, train_labels = data\n",
        "        train_data, train_labels  = train_data.to(device), train_labels.to(device)\n",
        "        y_pred = model(train_data)\n",
        "        loss = CELoss(y_pred, train_labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "            \n",
        "        # validation  \n",
        "        if idx % 20 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():    \n",
        "                test_pred = []\n",
        "                test_true = [] \n",
        "                for jdx, data in enumerate(testloader):\n",
        "                    test_data, test_labels = data\n",
        "                    test_data = test_data.to(device)\n",
        "                    y_pred = model(test_data)\n",
        "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
        "                    test_true.append(test_labels.numpy())\n",
        "                \n",
        "                test_true = np.concatenate(test_true)\n",
        "                test_pred = np.concatenate(test_pred)\n",
        "                val_auc_mean =  roc_auc_score(test_true, test_pred) \n",
        "                model.train()\n",
        "\n",
        "                if best_val_auc < val_auc_mean:\n",
        "                    best_val_auc = val_auc_mean\n",
        "                    torch.save(model.state_dict(), 'Resnet34_pretrained_model.pth')\n",
        "\n",
        "                print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9MIv8GpTZpn",
        "outputId": "9c92b86e-29d6-4d35-fa40-f6808a8d2a2a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-label mode: True, Number of classes: [5]\n",
            "------------------------------\n",
            "Found 2384 images in total, 300 positive images, 2084 negative images\n",
            "Cardiomegaly(C0): imbalance ratio is 0.1258\n",
            "\n",
            "Found 2384 images in total, 695 positive images, 1689 negative images\n",
            "Edema(C1): imbalance ratio is 0.2915\n",
            "\n",
            "Found 2384 images in total, 147 positive images, 2237 negative images\n",
            "Consolidation(C2): imbalance ratio is 0.0617\n",
            "\n",
            "Found 2384 images in total, 687 positive images, 1697 negative images\n",
            "Atelectasis(C3): imbalance ratio is 0.2882\n",
            "\n",
            "Found 2384 images in total, 918 positive images, 1466 negative images\n",
            "Pleural Effusion(C4): imbalance ratio is 0.3851\n",
            "\n",
            "Multi-label mode: True, Number of classes: [5]\n",
            "------------------------------\n",
            "Found 398 images in total, 60 positive images, 338 negative images\n",
            "Cardiomegaly(C0): imbalance ratio is 0.1508\n",
            "\n",
            "Found 398 images in total, 107 positive images, 291 negative images\n",
            "Edema(C1): imbalance ratio is 0.2688\n",
            "\n",
            "Found 398 images in total, 25 positive images, 373 negative images\n",
            "Consolidation(C2): imbalance ratio is 0.0628\n",
            "\n",
            "Found 398 images in total, 111 positive images, 287 negative images\n",
            "Atelectasis(C3): imbalance ratio is 0.2789\n",
            "\n",
            "Found 398 images in total, 171 positive images, 227 negative images\n",
            "Pleural Effusion(C4): imbalance ratio is 0.4296\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/libauc/datasets/chexpert.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
            "/usr/local/lib/python3.7/dist-packages/libauc/datasets/chexpert.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=0, BatchID=0, Val_AUC=0.4868, Best_Val_AUC=0.4868\n",
            "Epoch=0, BatchID=20, Val_AUC=0.5902, Best_Val_AUC=0.5902\n",
            "Epoch=0, BatchID=40, Val_AUC=0.6581, Best_Val_AUC=0.6581\n",
            "Epoch=0, BatchID=60, Val_AUC=0.6682, Best_Val_AUC=0.6682\n",
            "Epoch=0, BatchID=80, Val_AUC=0.6658, Best_Val_AUC=0.6682\n",
            "Epoch=0, BatchID=100, Val_AUC=0.7007, Best_Val_AUC=0.7007\n",
            "Epoch=0, BatchID=120, Val_AUC=0.6896, Best_Val_AUC=0.7007\n",
            "Epoch=0, BatchID=140, Val_AUC=0.7027, Best_Val_AUC=0.7027\n",
            "Epoch=0, BatchID=160, Val_AUC=0.7344, Best_Val_AUC=0.7344\n",
            "Epoch=0, BatchID=180, Val_AUC=0.7544, Best_Val_AUC=0.7544\n",
            "Epoch=0, BatchID=200, Val_AUC=0.7535, Best_Val_AUC=0.7544\n",
            "Epoch=0, BatchID=220, Val_AUC=0.7608, Best_Val_AUC=0.7608\n",
            "Epoch=1, BatchID=0, Val_AUC=0.7770, Best_Val_AUC=0.7770\n",
            "Epoch=1, BatchID=20, Val_AUC=0.7903, Best_Val_AUC=0.7903\n",
            "Epoch=1, BatchID=40, Val_AUC=0.7832, Best_Val_AUC=0.7903\n",
            "Epoch=1, BatchID=60, Val_AUC=0.7888, Best_Val_AUC=0.7903\n",
            "Epoch=1, BatchID=80, Val_AUC=0.7955, Best_Val_AUC=0.7955\n",
            "Epoch=1, BatchID=100, Val_AUC=0.8162, Best_Val_AUC=0.8162\n",
            "Epoch=1, BatchID=120, Val_AUC=0.7870, Best_Val_AUC=0.8162\n",
            "Epoch=1, BatchID=140, Val_AUC=0.8063, Best_Val_AUC=0.8162\n",
            "Epoch=1, BatchID=160, Val_AUC=0.7998, Best_Val_AUC=0.8162\n",
            "Epoch=1, BatchID=180, Val_AUC=0.8122, Best_Val_AUC=0.8162\n",
            "Epoch=1, BatchID=200, Val_AUC=0.8155, Best_Val_AUC=0.8162\n",
            "Epoch=1, BatchID=220, Val_AUC=0.8189, Best_Val_AUC=0.8189\n",
            "Epoch=2, BatchID=0, Val_AUC=0.8206, Best_Val_AUC=0.8206\n",
            "Epoch=2, BatchID=20, Val_AUC=0.8287, Best_Val_AUC=0.8287\n",
            "Epoch=2, BatchID=40, Val_AUC=0.8551, Best_Val_AUC=0.8551\n",
            "Epoch=2, BatchID=60, Val_AUC=0.8464, Best_Val_AUC=0.8551\n",
            "Epoch=2, BatchID=80, Val_AUC=0.8488, Best_Val_AUC=0.8551\n",
            "Epoch=2, BatchID=100, Val_AUC=0.8359, Best_Val_AUC=0.8551\n",
            "Epoch=2, BatchID=120, Val_AUC=0.8491, Best_Val_AUC=0.8551\n",
            "Epoch=2, BatchID=140, Val_AUC=0.8620, Best_Val_AUC=0.8620\n",
            "Epoch=2, BatchID=160, Val_AUC=0.8734, Best_Val_AUC=0.8734\n",
            "Epoch=2, BatchID=180, Val_AUC=0.8806, Best_Val_AUC=0.8806\n",
            "Epoch=2, BatchID=200, Val_AUC=0.8609, Best_Val_AUC=0.8806\n",
            "Epoch=2, BatchID=220, Val_AUC=0.8872, Best_Val_AUC=0.8872\n",
            "Epoch=3, BatchID=0, Val_AUC=0.8707, Best_Val_AUC=0.8872\n",
            "Epoch=3, BatchID=20, Val_AUC=0.8692, Best_Val_AUC=0.8872\n",
            "Epoch=3, BatchID=40, Val_AUC=0.8771, Best_Val_AUC=0.8872\n",
            "Epoch=3, BatchID=60, Val_AUC=0.8777, Best_Val_AUC=0.8872\n",
            "Epoch=3, BatchID=80, Val_AUC=0.8660, Best_Val_AUC=0.8872\n",
            "Epoch=3, BatchID=100, Val_AUC=0.8873, Best_Val_AUC=0.8873\n",
            "Epoch=3, BatchID=120, Val_AUC=0.9000, Best_Val_AUC=0.9000\n",
            "Epoch=3, BatchID=140, Val_AUC=0.8916, Best_Val_AUC=0.9000\n",
            "Epoch=3, BatchID=160, Val_AUC=0.8964, Best_Val_AUC=0.9000\n",
            "Epoch=3, BatchID=180, Val_AUC=0.8776, Best_Val_AUC=0.9000\n",
            "Epoch=3, BatchID=200, Val_AUC=0.9001, Best_Val_AUC=0.9001\n",
            "Epoch=3, BatchID=220, Val_AUC=0.9013, Best_Val_AUC=0.9013\n",
            "Epoch=4, BatchID=0, Val_AUC=0.9118, Best_Val_AUC=0.9118\n",
            "Epoch=4, BatchID=20, Val_AUC=0.9186, Best_Val_AUC=0.9186\n",
            "Epoch=4, BatchID=40, Val_AUC=0.9334, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=60, Val_AUC=0.9214, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=80, Val_AUC=0.9170, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=100, Val_AUC=0.9285, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=120, Val_AUC=0.9246, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=140, Val_AUC=0.9090, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=160, Val_AUC=0.9224, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=180, Val_AUC=0.9231, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=200, Val_AUC=0.9087, Best_Val_AUC=0.9334\n",
            "Epoch=4, BatchID=220, Val_AUC=0.9380, Best_Val_AUC=0.9380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Val_AUC=%.4f, Best_Val_AUC=%.4f'%(val_auc_mean, best_val_auc ))"
      ],
      "metadata": {
        "id": "dJO2cH-nWPci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3dcec9-8339-4242-c6fa-c7ef4646591c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val_AUC=0.9380, Best_Val_AUC=0.9380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from libauc.models.resnet import resnet34\n",
        "# # dataloader\n",
        "data_root = '/content/drive/MyDrive/Deep Learning Project/CheXpert-v1.0-small/'\n",
        "\n",
        "# Index: -1 denotes multi-label mode including 5 diseases\n",
        "traindSet = CheXpert(csv_path=data_root+'Chexpert_train.csv', image_root_path=data_root, use_upsampling=False, use_frontal=True, image_size=224, mode='train', class_index=-1)\n",
        "testSet =  CheXpert(csv_path=data_root+'Chexpert_valid.csv',  image_root_path=data_root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=-1)\n",
        "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=10, num_workers=2, shuffle=True)\n",
        "testloader =  torch.utils.data.DataLoader(testSet, batch_size=10, num_workers=2, shuffle=False)\n",
        "\n",
        "# # paramaters\n",
        "SEED = 123\n",
        "BATCH_SIZE = 10\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-5\n",
        "\n",
        "# # model\n",
        "# set_all_seeds(SEED)\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = resnet34(pretrained=True, last_activation=None, activations='relu', num_classes=5)\n",
        "model = model.to(device)\n",
        "\n",
        "# define loss & optimizer\n",
        "CELoss = CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
        "# training\n",
        "best_val_auc = 0 \n",
        "for epoch in range(5):\n",
        "    for idx, data in enumerate(trainloader):\n",
        "      #with torch.no_grad():\n",
        "        #print(gpu_usage())\n",
        "        torch.cuda.empty_cache()\n",
        "        train_data, train_labels = data\n",
        "        train_data, train_labels  = train_data.to(device), train_labels.to(device)\n",
        "        y_pred = model(train_data)\n",
        "        loss = CELoss(y_pred, train_labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "            \n",
        "        # validation  \n",
        "        if idx % 20 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():    \n",
        "                test_pred = []\n",
        "                test_true = [] \n",
        "                for jdx, data in enumerate(testloader):\n",
        "                    test_data, test_labels = data\n",
        "                    test_data = test_data.to(device)\n",
        "                    y_pred = model(test_data)\n",
        "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
        "                    test_true.append(test_labels.numpy())\n",
        "                \n",
        "                test_true = np.concatenate(test_true)\n",
        "                test_pred = np.concatenate(test_pred)\n",
        "                val_auc_mean =  roc_auc_score(test_true, test_pred) \n",
        "                model.train()\n",
        "\n",
        "                if best_val_auc < val_auc_mean:\n",
        "                    best_val_auc = val_auc_mean\n",
        "                    torch.save(model.state_dict(), 'ce_pretrained_model.pth')\n",
        "\n",
        "                print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKEuB4Q0Zycx",
        "outputId": "b8f9b0ad-cd08-47fb-a549-48432d5284d6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-label mode: True, Number of classes: [5]\n",
            "------------------------------\n",
            "Found 2384 images in total, 300 positive images, 2084 negative images\n",
            "Cardiomegaly(C0): imbalance ratio is 0.1258\n",
            "\n",
            "Found 2384 images in total, 695 positive images, 1689 negative images\n",
            "Edema(C1): imbalance ratio is 0.2915\n",
            "\n",
            "Found 2384 images in total, 147 positive images, 2237 negative images\n",
            "Consolidation(C2): imbalance ratio is 0.0617\n",
            "\n",
            "Found 2384 images in total, 687 positive images, 1697 negative images\n",
            "Atelectasis(C3): imbalance ratio is 0.2882\n",
            "\n",
            "Found 2384 images in total, 918 positive images, 1466 negative images\n",
            "Pleural Effusion(C4): imbalance ratio is 0.3851\n",
            "\n",
            "Multi-label mode: True, Number of classes: [5]\n",
            "------------------------------\n",
            "Found 398 images in total, 60 positive images, 338 negative images\n",
            "Cardiomegaly(C0): imbalance ratio is 0.1508\n",
            "\n",
            "Found 398 images in total, 107 positive images, 291 negative images\n",
            "Edema(C1): imbalance ratio is 0.2688\n",
            "\n",
            "Found 398 images in total, 25 positive images, 373 negative images\n",
            "Consolidation(C2): imbalance ratio is 0.0628\n",
            "\n",
            "Found 398 images in total, 111 positive images, 287 negative images\n",
            "Atelectasis(C3): imbalance ratio is 0.2789\n",
            "\n",
            "Found 398 images in total, 171 positive images, 227 negative images\n",
            "Pleural Effusion(C4): imbalance ratio is 0.4296\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/libauc/datasets/chexpert.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
            "/usr/local/lib/python3.7/dist-packages/libauc/datasets/chexpert.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=0, BatchID=0, Val_AUC=0.5268, Best_Val_AUC=0.5268\n",
            "Epoch=0, BatchID=20, Val_AUC=0.6579, Best_Val_AUC=0.6579\n",
            "Epoch=0, BatchID=40, Val_AUC=0.6696, Best_Val_AUC=0.6696\n",
            "Epoch=0, BatchID=60, Val_AUC=0.6951, Best_Val_AUC=0.6951\n",
            "Epoch=0, BatchID=80, Val_AUC=0.7122, Best_Val_AUC=0.7122\n",
            "Epoch=0, BatchID=100, Val_AUC=0.7279, Best_Val_AUC=0.7279\n",
            "Epoch=0, BatchID=120, Val_AUC=0.7445, Best_Val_AUC=0.7445\n",
            "Epoch=0, BatchID=140, Val_AUC=0.7604, Best_Val_AUC=0.7604\n",
            "Epoch=0, BatchID=160, Val_AUC=0.7613, Best_Val_AUC=0.7613\n",
            "Epoch=0, BatchID=180, Val_AUC=0.7781, Best_Val_AUC=0.7781\n",
            "Epoch=0, BatchID=200, Val_AUC=0.7889, Best_Val_AUC=0.7889\n",
            "Epoch=0, BatchID=220, Val_AUC=0.7811, Best_Val_AUC=0.7889\n",
            "Epoch=1, BatchID=0, Val_AUC=0.7723, Best_Val_AUC=0.7889\n",
            "Epoch=1, BatchID=20, Val_AUC=0.7710, Best_Val_AUC=0.7889\n",
            "Epoch=1, BatchID=40, Val_AUC=0.7798, Best_Val_AUC=0.7889\n",
            "Epoch=1, BatchID=60, Val_AUC=0.7868, Best_Val_AUC=0.7889\n",
            "Epoch=1, BatchID=80, Val_AUC=0.7884, Best_Val_AUC=0.7889\n",
            "Epoch=1, BatchID=100, Val_AUC=0.7860, Best_Val_AUC=0.7889\n",
            "Epoch=1, BatchID=120, Val_AUC=0.8011, Best_Val_AUC=0.8011\n",
            "Epoch=1, BatchID=140, Val_AUC=0.8023, Best_Val_AUC=0.8023\n",
            "Epoch=1, BatchID=160, Val_AUC=0.7955, Best_Val_AUC=0.8023\n",
            "Epoch=1, BatchID=180, Val_AUC=0.8153, Best_Val_AUC=0.8153\n",
            "Epoch=1, BatchID=200, Val_AUC=0.8268, Best_Val_AUC=0.8268\n",
            "Epoch=1, BatchID=220, Val_AUC=0.8074, Best_Val_AUC=0.8268\n",
            "Epoch=2, BatchID=0, Val_AUC=0.8071, Best_Val_AUC=0.8268\n",
            "Epoch=2, BatchID=20, Val_AUC=0.8141, Best_Val_AUC=0.8268\n",
            "Epoch=2, BatchID=40, Val_AUC=0.8384, Best_Val_AUC=0.8384\n",
            "Epoch=2, BatchID=60, Val_AUC=0.8357, Best_Val_AUC=0.8384\n",
            "Epoch=2, BatchID=80, Val_AUC=0.8448, Best_Val_AUC=0.8448\n",
            "Epoch=2, BatchID=100, Val_AUC=0.8575, Best_Val_AUC=0.8575\n",
            "Epoch=2, BatchID=120, Val_AUC=0.8565, Best_Val_AUC=0.8575\n",
            "Epoch=2, BatchID=140, Val_AUC=0.8551, Best_Val_AUC=0.8575\n",
            "Epoch=2, BatchID=160, Val_AUC=0.8643, Best_Val_AUC=0.8643\n",
            "Epoch=2, BatchID=180, Val_AUC=0.8507, Best_Val_AUC=0.8643\n",
            "Epoch=2, BatchID=200, Val_AUC=0.8578, Best_Val_AUC=0.8643\n",
            "Epoch=2, BatchID=220, Val_AUC=0.8337, Best_Val_AUC=0.8643\n",
            "Epoch=3, BatchID=0, Val_AUC=0.8640, Best_Val_AUC=0.8643\n",
            "Epoch=3, BatchID=20, Val_AUC=0.8780, Best_Val_AUC=0.8780\n",
            "Epoch=3, BatchID=40, Val_AUC=0.8840, Best_Val_AUC=0.8840\n",
            "Epoch=3, BatchID=60, Val_AUC=0.8723, Best_Val_AUC=0.8840\n",
            "Epoch=3, BatchID=80, Val_AUC=0.8714, Best_Val_AUC=0.8840\n",
            "Epoch=3, BatchID=100, Val_AUC=0.8615, Best_Val_AUC=0.8840\n",
            "Epoch=3, BatchID=120, Val_AUC=0.8711, Best_Val_AUC=0.8840\n",
            "Epoch=3, BatchID=140, Val_AUC=0.8504, Best_Val_AUC=0.8840\n",
            "Epoch=3, BatchID=160, Val_AUC=0.8710, Best_Val_AUC=0.8840\n",
            "Epoch=3, BatchID=180, Val_AUC=0.8805, Best_Val_AUC=0.8840\n",
            "Epoch=3, BatchID=200, Val_AUC=0.8846, Best_Val_AUC=0.8846\n",
            "Epoch=3, BatchID=220, Val_AUC=0.9017, Best_Val_AUC=0.9017\n",
            "Epoch=4, BatchID=0, Val_AUC=0.9028, Best_Val_AUC=0.9028\n",
            "Epoch=4, BatchID=20, Val_AUC=0.9033, Best_Val_AUC=0.9033\n",
            "Epoch=4, BatchID=40, Val_AUC=0.9001, Best_Val_AUC=0.9033\n",
            "Epoch=4, BatchID=60, Val_AUC=0.8990, Best_Val_AUC=0.9033\n",
            "Epoch=4, BatchID=80, Val_AUC=0.8860, Best_Val_AUC=0.9033\n",
            "Epoch=4, BatchID=100, Val_AUC=0.8971, Best_Val_AUC=0.9033\n",
            "Epoch=4, BatchID=120, Val_AUC=0.9013, Best_Val_AUC=0.9033\n",
            "Epoch=4, BatchID=140, Val_AUC=0.9114, Best_Val_AUC=0.9114\n",
            "Epoch=4, BatchID=160, Val_AUC=0.9159, Best_Val_AUC=0.9159\n",
            "Epoch=4, BatchID=180, Val_AUC=0.9078, Best_Val_AUC=0.9159\n",
            "Epoch=4, BatchID=200, Val_AUC=0.9112, Best_Val_AUC=0.9159\n",
            "Epoch=4, BatchID=220, Val_AUC=0.9106, Best_Val_AUC=0.9159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Val_AUC=%.4f, Best_Val_AUC=%.4f'%(val_auc_mean, best_val_auc ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqgmlrDOaG5M",
        "outputId": "d752debe-6144-4e27-88ad-5c77d7d82b3c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val_AUC=0.9106, Best_Val_AUC=0.9159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP4adNO97YBV"
      },
      "source": [
        "# **Optimizing AUCM Loss**\n",
        "\n",
        "\n",
        "*   Binary Classification\n",
        "*   PESG + AUCM Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "oiOrKatkSCNJ"
      },
      "outputs": [],
      "source": [
        "# # parameters\n",
        "# class_id = 1 # 0:Cardiomegaly, 1:Edema, 2:Consolidation, 3:Atelectasis, 4:Pleural Effusion \n",
        "# root = '/content/drive/MyDrive/Chexpert_Dataset/'\n",
        "\n",
        "# # You can set use_upsampling=True and pass the class name by upsampling_cols=['Cardiomegaly'] to do upsampling. This may improve the performance\n",
        "# traindSet = CheXpert(csv_path=root+'valid.csv', image_root_path=root, use_upsampling=True, use_frontal=True, image_size=224, mode='train', class_index=class_id)\n",
        "# testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=class_id)\n",
        "# trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=10, num_workers=2, shuffle=True)\n",
        "# testloader =  torch.utils.data.DataLoader(testSet, batch_size=10, num_workers=2, shuffle=False)\n",
        "\n",
        "# # paramaters\n",
        "# SEED = 123\n",
        "# BATCH_SIZE = 10\n",
        "# imratio = traindSet.imratio\n",
        "# lr = 0.05 # using smaller learning rate is better\n",
        "# gamma = 500\n",
        "# weight_decay = 1e-5\n",
        "# margin = 1.0\n",
        "\n",
        "# # model\n",
        "# set_all_seeds(SEED)\n",
        "# model = DenseNet121(pretrained=False, last_activation='sigmoid', activations='relu', num_classes=1)\n",
        "# model = model.cuda()\n",
        "\n",
        "\n",
        "# # load pretrained model\n",
        "# if True:\n",
        "#   PATH = 'ce_pretrained_model.pth' \n",
        "#   state_dict = torch.load(PATH)\n",
        "#   state_dict.pop('classifier.weight', None)\n",
        "#   state_dict.pop('classifier.bias', None) \n",
        "#   model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "\n",
        "# # define loss & optimizer\n",
        "# Loss = AUCMLoss(imratio=imratio)\n",
        "# optimizer = PESG(model, \n",
        "#                  a=Loss.a, \n",
        "#                  b=Loss.b, \n",
        "#                  alpha=Loss.alpha, \n",
        "#                  imratio=imratio, \n",
        "#                  lr=lr, \n",
        "#                  gamma=gamma, \n",
        "#                  margin=margin, \n",
        "#                  weight_decay=weight_decay)\n",
        "\n",
        "# best_val_auc = 0\n",
        "# for epoch in range(5):\n",
        "#   if epoch > 0:\n",
        "#      optimizer.update_regularizer(decay_factor=10)\n",
        "#   for idx, data in enumerate(trainloader):\n",
        "#       train_data, train_labels = data\n",
        "#       train_data, train_labels = train_data.cuda(), train_labels.cuda()\n",
        "#       y_pred = model(train_data)\n",
        "#       loss = Loss(y_pred, train_labels)\n",
        "#       optimizer.zero_grad()\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "\n",
        "#       # validation\n",
        "#       if idx % 20 == 0:\n",
        "#         model.eval()\n",
        "#         with torch.no_grad():    \n",
        "#               test_pred = []\n",
        "#               test_true = [] \n",
        "#               for jdx, data in enumerate(testloader):\n",
        "#                   test_data, test_label = data\n",
        "#                   test_data = test_data.cuda()\n",
        "#                   y_pred = model(test_data)\n",
        "#                   test_pred.append(y_pred.cpu().detach().numpy())\n",
        "#                   test_true.append(test_label.numpy())\n",
        "              \n",
        "#               test_true = np.concatenate(test_true)\n",
        "#               test_pred = np.concatenate(test_pred)\n",
        "#               val_auc =  roc_auc_score(test_true, test_pred) \n",
        "#               model.train()\n",
        "\n",
        "#               if best_val_auc < val_auc:\n",
        "#                  best_val_auc = val_auc\n",
        "              \n",
        "#         print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, lr=%.4f'%(epoch, idx, val_auc,  optimizer.lr))\n",
        "\n",
        "# print ('Best Val_AUC is %.4f'%best_val_auc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "05_Optimizing_AUROC_Loss_with_DenseNet121_on_CheXpert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}